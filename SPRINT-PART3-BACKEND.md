# ‚öôÔ∏è AI Design Studio - Sprint Documentation Part 3
## Backend & AI Service Development

> **For Students**: This part covers building the Node.js backend API and Python AI service with Stable Diffusion and SAM.

---

## üéØ Sprint Overview

**Sprint Duration**: Week 3-4  
**Goal**: Build backend APIs and integrate AI models  
**Key Deliverables**: REST API, AI generation service, SAM segmentation, file handling

---

## üìñ Table of Contents

1. [Node.js Server Setup](#nodejs-server-setup)
2. [Express.js API Routes](#expressjs-api-routes)
3. [File Upload & Storage](#file-upload--storage)
4. [Python Flask AI Service](#python-flask-ai-service)
5. [Stable Diffusion Integration](#stable-diffusion-integration)
6. [SAM Segmentation](#sam-segmentation)
7. [WebSocket Real-time Features](#websocket-real-time-features)

---

## üöÄ Node.js Server Setup

### Server Entry Point (server/index.js)

```javascript
const express = require('express');
const cors = require('cors');
const http = require('http');
const socketIO = require('socket.io');
const path = require('path');
require('dotenv').config();

const app = express();
const server = http.createServer(app);
const io = socketIO(server, {
  cors: {
    origin: "*",
    methods: ["GET", "POST"]
  }
});

// Middleware
app.use(cors());                                    // Enable CORS
app.use(express.json({ limit: '50mb' }));          // Parse JSON (large limit for images)
app.use(express.urlencoded({ extended: true, limit: '50mb' }));
app.use(express.static(path.join(__dirname, '..'))); // Serve static files

// Import route modules
const projectRoutes = require('./routes/projects');
const aiRoutes = require('./routes/ai');
const assetRoutes = require('./routes/assets');
const samRoutes = require('./routes/sam');

// Register routes
app.use('/api/projects', projectRoutes);
app.use('/api/ai', aiRoutes);
app.use('/api/assets', assetRoutes);
app.use('/api/sam', samRoutes);

// Start server
const PORT = process.env.PORT || 3000;
server.listen(PORT, () => {
  console.log(`‚úì Server running on http://localhost:${PORT}`);
  console.log(`‚úì AI Service: ${process.env.AI_SERVICE_URL || 'http://localhost:5000'}`);
});

module.exports = { app, io };
```

**Key Concepts**:
- **CORS**: Allows frontend to call backend from different port
- **Body Parser**: Parses JSON and form data (50MB limit for images)
- **Static Files**: Serves HTML/CSS/JS files
- **Modular Routes**: Each feature has its own route file

---

## üõ§Ô∏è Express.js API Routes

### Project Routes (server/routes/projects.js)

```javascript
const express = require('express');
const router = express.Router();
const fs = require('fs').promises;
const path = require('path');
const { v4: uuidv4 } = require('uuid');

const PROJECTS_DIR = path.join(__dirname, '../../data/projects');

// Ensure projects directory exists
async function ensureDir() {
  try {
    await fs.access(PROJECTS_DIR);
  } catch {
    await fs.mkdir(PROJECTS_DIR, { recursive: true });
  }
}

// GET /api/projects - List all projects
router.get('/', async (req, res) => {
  try {
    await ensureDir();
    const files = await fs.readdir(PROJECTS_DIR);
    
    const projects = await Promise.all(
      files
        .filter(file => file.endsWith('.json'))
        .map(async (file) => {
          const content = await fs.readFile(
            path.join(PROJECTS_DIR, file),
            'utf-8'
          );
          return JSON.parse(content);
        })
    );
    
    res.json(projects);
  } catch (error) {
    console.error('Error listing projects:', error);
    res.status(500).json({ error: 'Failed to list projects' });
  }
});

// GET /api/projects/:id - Get single project
router.get('/:id', async (req, res) => {
  try {
    const projectPath = path.join(PROJECTS_DIR, `${req.params.id}.json`);
    const content = await fs.readFile(projectPath, 'utf-8');
    res.json(JSON.parse(content));
  } catch (error) {
    console.error('Error loading project:', error);
    res.status(404).json({ error: 'Project not found' });
  }
});

// POST /api/projects - Create new project
router.post('/', async (req, res) => {
  try {
    await ensureDir();
    
    const project = {
      id: uuidv4(),
      name: req.body.name || 'Untitled Project',
      created: new Date().toISOString(),
      updated: new Date().toISOString(),
      canvasData: req.body.canvasData || {},
      thumbnail: req.body.thumbnail || null
    };
    
    const projectPath = path.join(PROJECTS_DIR, `${project.id}.json`);
    await fs.writeFile(projectPath, JSON.stringify(project, null, 2));
    
    res.status(201).json(project);
  } catch (error) {
    console.error('Error creating project:', error);
    res.status(500).json({ error: 'Failed to create project' });
  }
});

// PUT /api/projects/:id - Update project
router.put('/:id', async (req, res) => {
  try {
    const projectPath = path.join(PROJECTS_DIR, `${req.params.id}.json`);
    
    const project = {
      id: req.params.id,
      name: req.body.name,
      created: req.body.created,
      updated: new Date().toISOString(),
      canvasData: req.body.canvasData,
      thumbnail: req.body.thumbnail
    };
    
    await fs.writeFile(projectPath, JSON.stringify(project, null, 2));
    res.json(project);
  } catch (error) {
    console.error('Error updating project:', error);
    res.status(500).json({ error: 'Failed to update project' });
  }
});

// DELETE /api/projects/:id - Delete project
router.delete('/:id', async (req, res) => {
  try {
    const projectPath = path.join(PROJECTS_DIR, `${req.params.id}.json`);
    await fs.unlink(projectPath);
    res.json({ success: true });
  } catch (error) {
    console.error('Error deleting project:', error);
    res.status(500).json({ error: 'Failed to delete project' });
  }
});

module.exports = router;
```

**CRUD Operations**:
- **C**reate - POST /api/projects
- **R**ead - GET /api/projects, GET /api/projects/:id
- **U**pdate - PUT /api/projects/:id
- **D**elete - DELETE /api/projects/:id

### AI Generation Routes (server/routes/ai.js)

```javascript
const express = require('express');
const router = express.Router();
const axios = require('axios');
const sharp = require('sharp');
const { v4: uuidv4 } = require('uuid');

const AI_SERVICE_URL = process.env.AI_SERVICE_URL || 'http://localhost:5000';

// POST /api/ai/generate - Generate image from prompt
router.post('/generate', async (req, res) => {
  try {
    const { prompt, width, height, style, seed, steps, guidance } = req.body;
    
    if (!prompt) {
      return res.status(400).json({ error: 'Prompt is required' });
    }
    
    console.log(`Generating image: "${prompt}"`);
    
    // Call Python AI service
    const response = await axios.post(
      `${AI_SERVICE_URL}/generate`,
      {
        prompt,
        width: width || 512,
        height: height || 512,
        seed: seed || null,
        num_inference_steps: steps || 50,
        guidance_scale: guidance || 7.5
      },
      {
        timeout: 120000 // 2 minute timeout
      }
    );
    
    const generatedImage = response.data;
    
    // Generate thumbnail (optional)
    let thumbnail = null;
    if (generatedImage.image_base64) {
      const base64Data = generatedImage.image_base64.replace(/^data:image\/\w+;base64,/, '');
      const buffer = Buffer.from(base64Data, 'base64');
      
      const thumbnailBuffer = await sharp(buffer)
        .resize(200, 200, { fit: 'cover' })
        .png()
        .toBuffer();
      
      thumbnail = `data:image/png;base64,${thumbnailBuffer.toString('base64')}`;
    }
    
    res.json({
      id: uuidv4(),
      prompt,
      imageBase64: generatedImage.image_base64,
      imageUrl: generatedImage.image_url,
      thumbnail,
      seed: generatedImage.seed,
      parameters: { width, height, steps, guidance },
      timestamp: new Date().toISOString()
    });
    
  } catch (error) {
    console.error('AI generation error:', error.message);
    
    if (error.code === 'ECONNREFUSED') {
      return res.status(503).json({ 
        error: 'AI service is not running. Please start the Python AI service.' 
      });
    }
    
    res.status(500).json({ 
      error: error.response?.data?.error || 'Failed to generate image' 
    });
  }
});

module.exports = router;
```

**Error Handling**:
- Connection refused ‚Üí AI service not running
- Timeout ‚Üí Generation taking too long
- Invalid parameters ‚Üí 400 Bad Request

---

## üìÅ File Upload & Storage

### Asset Upload Routes (server/routes/assets.js)

```javascript
const express = require('express');
const router = express.Router();
const multer = require('multer');
const path = require('path');
const fs = require('fs').promises;
const sharp = require('sharp');
const { v4: uuidv4 } = require('uuid');

const UPLOADS_DIR = path.join(__dirname, '../../data/uploads');

// Configure multer for file uploads
const storage = multer.diskStorage({
  destination: async (req, file, cb) => {
    try {
      await fs.access(UPLOADS_DIR);
    } catch {
      await fs.mkdir(UPLOADS_DIR, { recursive: true });
    }
    cb(null, UPLOADS_DIR);
  },
  filename: (req, file, cb) => {
    const uniqueName = `${uuidv4()}${path.extname(file.originalname)}`;
    cb(null, uniqueName);
  }
});

const upload = multer({
  storage,
  limits: {
    fileSize: 10 * 1024 * 1024 // 10MB limit
  },
  fileFilter: (req, file, cb) => {
    const allowedTypes = /jpeg|jpg|png|gif|webp|svg/;
    const extname = allowedTypes.test(path.extname(file.originalname).toLowerCase());
    const mimetype = allowedTypes.test(file.mimetype);
    
    if (extname && mimetype) {
      cb(null, true);
    } else {
      cb(new Error('Only image files are allowed'));
    }
  }
});

// POST /api/assets/upload - Upload image
router.post('/upload', upload.single('file'), async (req, res) => {
  try {
    if (!req.file) {
      return res.status(400).json({ error: 'No file uploaded' });
    }
    
    const filePath = req.file.path;
    
    // Generate thumbnail
    const thumbnailPath = path.join(
      UPLOADS_DIR,
      `thumb_${req.file.filename}`
    );
    
    await sharp(filePath)
      .resize(200, 200, { fit: 'cover' })
      .toFile(thumbnailPath);
    
    // Get image metadata
    const metadata = await sharp(filePath).metadata();
    
    res.json({
      id: uuidv4(),
      filename: req.file.filename,
      originalName: req.file.originalname,
      url: `/data/uploads/${req.file.filename}`,
      thumbnailUrl: `/data/uploads/thumb_${req.file.filename}`,
      size: req.file.size,
      width: metadata.width,
      height: metadata.height,
      format: metadata.format,
      uploaded: new Date().toISOString()
    });
    
  } catch (error) {
    console.error('Upload error:', error);
    res.status(500).json({ error: 'Failed to upload file' });
  }
});

// GET /api/assets - List all uploaded assets
router.get('/', async (req, res) => {
  try {
    const files = await fs.readdir(UPLOADS_DIR);
    
    const assets = files
      .filter(file => !file.startsWith('thumb_'))
      .map(file => ({
        filename: file,
        url: `/data/uploads/${file}`
      }));
    
    res.json(assets);
  } catch (error) {
    console.error('Error listing assets:', error);
    res.status(500).json({ error: 'Failed to list assets' });
  }
});

module.exports = router;
```

**Multer Configuration**:
- File size limit: 10MB
- Allowed types: Images only
- Auto-generate unique filenames
- Create thumbnails with Sharp

---

## üêç Python Flask AI Service

### Flask Server (ai-service/app.py)

```python
from flask import Flask, request, jsonify
from flask_cors import CORS
import torch
import base64
import io
import os
from PIL import Image
import numpy as np
from dotenv import load_dotenv

load_dotenv()

app = Flask(__name__)
CORS(app)

# Global model storage
models = {
    'text2img': None,
    'sam': None,
    'clip': None
}

def load_text2img_model():
    """Load Stable Diffusion model"""
    try:
        from diffusers import StableDiffusionPipeline
        
        model_id = os.getenv('TEXT2IMG_MODEL', 'stabilityai/stable-diffusion-2-1')
        print(f'Loading model: {model_id}...')
        
        pipe = StableDiffusionPipeline.from_pretrained(
            model_id,
            torch_dtype=torch.float16 if torch.cuda.is_available() else torch.float32
        )
        
        # Move to GPU if available
        if torch.cuda.is_available():
            pipe = pipe.to('cuda')
            print('‚úì Using GPU acceleration')
        else:
            print('‚ö† Using CPU (slower)')
        
        models['text2img'] = pipe
        print('‚úì Text-to-image model loaded successfully')
        
    except Exception as e:
        print(f'‚úó Failed to load text-to-image model: {e}')

def load_sam_model():
    """Load Segment Anything Model"""
    try:
        from segment_anything import sam_model_registry, SamAutomaticMaskGenerator, SamPredictor
        
        model_type = os.getenv('SAM_MODEL_TYPE', 'vit_h')
        checkpoint = os.getenv('SAM_CHECKPOINT', 'sam_vit_h_4b8939.pth')
        
        print(f'Loading SAM model: {model_type}...')
        
        sam = sam_model_registry[model_type](checkpoint=checkpoint)
        
        if torch.cuda.is_available():
            sam = sam.to('cuda')
        
        models['sam'] = {
            'model': sam,
            'predictor': SamPredictor(sam),
            'auto_mask_generator': SamAutomaticMaskGenerator(sam)
        }
        
        print('‚úì SAM model loaded successfully')
        
    except Exception as e:
        print(f'‚úó Failed to load SAM model: {e}')

# Initialize models on startup
@app.before_first_request
def init_models():
    print('üöÄ Initializing AI models...')
    load_text2img_model()
    load_sam_model()
    print('‚úì Initialization complete')

# Helper functions
def base64_to_image(base64_str):
    """Convert base64 to PIL Image"""
    image_data = base64.b64decode(base64_str.split(',')[-1])
    return Image.open(io.BytesIO(image_data)).convert('RGB')

def image_to_base64(image):
    """Convert PIL Image to base64"""
    buffered = io.BytesIO()
    image.save(buffered, format='PNG')
    return base64.b64encode(buffered.getvalue()).decode('utf-8')

# Routes
@app.route('/health', methods=['GET'])
def health():
    """Health check endpoint"""
    return jsonify({
        'status': 'healthy',
        'gpu_available': torch.cuda.is_available(),
        'models_loaded': {
            'text2img': models['text2img'] is not None,
            'sam': models['sam'] is not None,
            'clip': models['clip'] is not None
        }
    })

@app.route('/generate', methods=['POST'])
def generate_image():
    """Generate image from text prompt using Stable Diffusion"""
    try:
        data = request.json
        prompt = data.get('prompt')
        width = data.get('width', 512)
        height = data.get('height', 512)
        seed = data.get('seed')
        steps = data.get('num_inference_steps', 50)
        guidance = data.get('guidance_scale', 7.5)
        
        # Validation
        if not prompt:
            return jsonify({'error': 'Prompt is required'}), 400
        
        if models['text2img'] is None:
            return jsonify({'error': 'Text-to-image model not loaded'}), 503
        
        print(f'Generating: "{prompt}" ({width}x{height})')
        
        # Set seed for reproducibility
        generator = None
        if seed is not None:
            device = 'cuda' if torch.cuda.is_available() else 'cpu'
            generator = torch.Generator(device=device)
            generator.manual_seed(int(seed))
        
        # Generate image
        result = models['text2img'](
            prompt,
            width=width,
            height=height,
            num_inference_steps=steps,
            guidance_scale=guidance,
            generator=generator
        )
        
        # Convert to base64
        image = result.images[0]
        image_base64 = image_to_base64(image)
        
        print('‚úì Generation complete')
        
        return jsonify({
            'image_base64': f'data:image/png;base64,{image_base64}',
            'image_url': None,
            'seed': seed or 0,
            'prompt': prompt
        })
        
    except Exception as e:
        print(f'‚úó Generation error: {e}')
        return jsonify({'error': str(e)}), 500

if __name__ == '__main__':
    port = int(os.getenv('PYTHON_AI_PORT', 5000))
    print(f'üöÄ Starting AI service on port {port}')
    app.run(host='0.0.0.0', port=port, debug=True)
```

**Key Features**:
- **Lazy Loading**: Models load on first request (saves startup time)
- **GPU Detection**: Automatically uses GPU if available
- **Error Handling**: Graceful fallbacks
- **Health Check**: Monitor model status

---

## üé® Stable Diffusion Integration

### Understanding the Generation Pipeline

```python
# 1. Load pretrained model
pipe = StableDiffusionPipeline.from_pretrained(
    'stabilityai/stable-diffusion-2-1',
    torch_dtype=torch.float16  # Use half precision for faster inference
)

# 2. Move to GPU
pipe = pipe.to('cuda')

# 3. Generate image
result = pipe(
    prompt="a beautiful sunset over mountains",
    width=512,
    height=512,
    num_inference_steps=50,      # More steps = higher quality
    guidance_scale=7.5,           # How closely to follow prompt
    generator=torch.Generator().manual_seed(42)  # For reproducibility
)

# 4. Get resulting image
image = result.images[0]
```

**Parameters Explained**:
- `num_inference_steps` (20-100): Denoising steps. More = better quality but slower
- `guidance_scale` (1-20): Prompt adherence. 7-9 is sweet spot
- `seed`: Random seed for reproducible results

---

## üîç SAM Segmentation

### SAM Integration (server/routes/sam.js)

```javascript
const express = require('express');
const router = express.Router();
const axios = require('axios');

const AI_SERVICE_URL = process.env.AI_SERVICE_URL || 'http://localhost:5000';

// POST /api/sam/segment - Segment image using SAM
router.post('/segment', async (req, res) => {
  try {
    const { image, points, labels, threshold } = req.body;
    
    if (!image) {
      return res.status(400).json({ error: 'Image is required' });
    }
    
    console.log('Segmenting image with SAM...');
    
    const response = await axios.post(
      `${AI_SERVICE_URL}/sam/segment`,
      {
        image,
        points: points || null,
        labels: labels || null,
        threshold: threshold || 0.5
      },
      {
        timeout: 60000 // 1 minute timeout
      }
    );
    
    console.log(`‚úì Found ${response.data.masks.length} segments`);
    
    res.json(response.data);
    
  } catch (error) {
    console.error('SAM segmentation error:', error.message);
    res.status(500).json({ 
      error: error.response?.data?.error || 'Failed to segment image' 
    });
  }
});

module.exports = router;
```

### Python SAM Implementation

```python
@app.route('/sam/segment', methods=['POST'])
def segment_image():
    """Segment image using SAM"""
    try:
        data = request.json
        image_base64 = data.get('image')
        points = data.get('points')  # [[x, y], ...]
        threshold = data.get('threshold', 0.5)
        
        if models['sam'] is None:
            return jsonify({'error': 'SAM model not loaded'}), 503
        
        # Convert image
        image = base64_to_image(image_base64)
        image_np = np.array(image)
        
        # Auto segmentation (no points provided)
        if points is None:
            print('Running automatic segmentation...')
            masks = models['sam']['auto_mask_generator'].generate(image_np)
            
            # Filter and format masks
            filtered_masks = []
            for i, mask in enumerate(masks[:10]):  # Top 10 masks
                if mask['stability_score'] >= threshold:
                    filtered_masks.append({
                        'bbox': {
                            'x': int(mask['bbox'][0]),
                            'y': int(mask['bbox'][1]),
                            'width': int(mask['bbox'][2]),
                            'height': int(mask['bbox'][3])
                        },
                        'confidence': float(mask['stability_score']),
                        'area': int(mask['area']),
                        'predicted_label': f'Object {i+1}'
                    })
            
            return jsonify({
                'masks': filtered_masks,
                'width': image.width,
                'height': image.height
            })
        
    except Exception as e:
        print(f'‚úó Segmentation error: {e}')
        return jsonify({'error': str(e)}), 500
```

**SAM Features**:
- Automatic mask generation (no user input)
- Point-based segmentation (click to select)
- Bounding box segmentation
- Confidence scores for each mask

---

## üîå WebSocket Real-time Features

### Socket.IO Setup (server/index.js)

```javascript
const activeProjects = new Map();

io.on('connection', (socket) => {
  console.log('‚úì Client connected:', socket.id);

  // Join project room
  socket.on('join-project', (projectId) => {
    socket.join(projectId);
    
    if (!activeProjects.has(projectId)) {
      activeProjects.set(projectId, new Set());
    }
    activeProjects.get(projectId).add(socket.id);
    
    // Notify others
    socket.to(projectId).emit('user-joined', {
      userId: socket.id,
      timestamp: Date.now()
    });
    
    console.log(`User ${socket.id} joined project ${projectId}`);
  });

  // Broadcast project updates
  socket.on('project-update', (data) => {
    socket.to(data.projectId).emit('project-update', {
      ...data,
      userId: socket.id
    });
  });

  // Handle disconnection
  socket.on('disconnect', () => {
    console.log('‚úó Client disconnected:', socket.id);
    
    activeProjects.forEach((users, projectId) => {
      if (users.has(socket.id)) {
        users.delete(socket.id);
        socket.to(projectId).emit('user-left', {
          userId: socket.id
        });
      }
    });
  });
});
```

**Use Cases**:
- Real-time collaboration
- Live cursor tracking
- Presence indicators
- Auto-save notifications

---

## üìö Key Learnings

### Backend Best Practices
‚úÖ **Modular Routes** - Each feature in separate file  
‚úÖ **Error Handling** - Try-catch with meaningful messages  
‚úÖ **Validation** - Check inputs before processing  
‚úÖ **CORS** - Enable cross-origin requests  
‚úÖ **File Limits** - Prevent DOS attacks  

### AI Service Best Practices
‚úÖ **Lazy Loading** - Load models only when needed  
‚úÖ **GPU Detection** - Automatic hardware optimization  
‚úÖ **Timeouts** - Prevent hanging requests  
‚úÖ **Health Checks** - Monitor service status  

### Common Issues & Solutions

**Problem**: AI service connection refused  
**Solution**: Ensure Python service is running on correct port

**Problem**: GPU out of memory  
**Solution**: Use CPU mode or reduce image size

**Problem**: Slow generation  
**Solution**: Reduce inference steps or use smaller model

---

## üéì Student Exercises

1. **Add API Endpoint**: Create `/api/projects/:id/duplicate`
2. **Implement Caching**: Use Redis for generated images
3. **Add Rate Limiting**: Prevent API abuse
4. **Error Logging**: Send errors to Sentry
5. **Add Authentication**: JWT token-based auth

---

## ‚è≠Ô∏è Next Steps

Continue to **SPRINT-PART4-INTEGRATION.md** to learn:
- Frontend-backend integration
- Testing strategies
- Docker deployment
- CI/CD pipeline

---

**Sprint 3 Complete! ‚ú®**  
*Backend and AI services are fully operational.*
